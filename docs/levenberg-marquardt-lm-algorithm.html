<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 3 Levenberg-Marquardt (LM) algorithm | Non-linear regression</title>
  <meta name="description" content="<p>This is a minimal example of using the bookdown package to write a book.
set in the _output.yml file.
The HTML output format for this example is bookdown::gitbook,</p>" />
  <meta name="generator" content="bookdown 0.42 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 3 Levenberg-Marquardt (LM) algorithm | Non-linear regression" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="<p>This is a minimal example of using the bookdown package to write a book.
set in the _output.yml file.
The HTML output format for this example is bookdown::gitbook,</p>" />
  <meta name="github-repo" content="rstudio/bookdown-demo" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 3 Levenberg-Marquardt (LM) algorithm | Non-linear regression" />
  
  <meta name="twitter:description" content="<p>This is a minimal example of using the bookdown package to write a book.
set in the _output.yml file.
The HTML output format for this example is bookdown::gitbook,</p>" />
  

<meta name="author" content="Kyungmin In, GCCL" />


<meta name="date" content="2025-04-01" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="the-gauss-newton-method.html"/>
<link rel="next" href="applying-the-lm-algorithm-to-a-damped-oscillation-model.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<link href="libs/htmltools-fill-0.5.8.1/fill.css" rel="stylesheet" />
<script src="libs/htmlwidgets-1.6.4/htmlwidgets.js"></script>
<script src="libs/plotly-binding-4.10.4/plotly.js"></script>
<script src="libs/typedarray-0.1/typedarray.min.js"></script>
<link href="libs/crosstalk-1.2.1/css/crosstalk.min.css" rel="stylesheet" />
<script src="libs/crosstalk-1.2.1/js/crosstalk.min.js"></script>
<link href="libs/plotly-htmlwidgets-css-2.11.1/plotly-htmlwidgets.css" rel="stylesheet" />
<script src="libs/plotly-main-2.11.1/plotly-latest.min.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Non-linear regression</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Non-Linear Regression and Optimization Methods in LBA Data Analysis</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#key-optimization-methods-in-non-linear-regression"><i class="fa fa-check"></i>Key Optimization Methods in Non-Linear Regression</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#the-levenberg-marquardt-algorithm-a-hybrid-approach"><i class="fa fa-check"></i>The Levenberg-Marquardt Algorithm: A Hybrid Approach</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#why-should-we-care-about-these-optimization-methods"><i class="fa fa-check"></i>Why Should We Care About These Optimization Methods?</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#practical-implementation-in-r"><i class="fa fa-check"></i>Practical Implementation in R</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="author.html"><a href="author.html"><i class="fa fa-check"></i>Author</a></li>
<li class="chapter" data-level="1" data-path="the-gradient-descent-method.html"><a href="the-gradient-descent-method.html"><i class="fa fa-check"></i><b>1</b> The Gradient descent method</a>
<ul>
<li class="chapter" data-level="1.1" data-path="the-gradient-descent-method.html"><a href="the-gradient-descent-method.html#computation-of-the-chi-squared-function"><i class="fa fa-check"></i><b>1.1</b> Computation of the chi-squared function</a></li>
<li class="chapter" data-level="1.2" data-path="the-gradient-descent-method.html"><a href="the-gradient-descent-method.html#computation-of-the-gradient"><i class="fa fa-check"></i><b>1.2</b> Computation of the gradient</a></li>
<li class="chapter" data-level="1.3" data-path="the-gradient-descent-method.html"><a href="the-gradient-descent-method.html#the-parameter-updating"><i class="fa fa-check"></i><b>1.3</b> The parameter updating</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="the-gauss-newton-method.html"><a href="the-gauss-newton-method.html"><i class="fa fa-check"></i><b>2</b> The Gauss-Newton Method</a>
<ul>
<li class="chapter" data-level="2.1" data-path="the-gauss-newton-method.html"><a href="the-gauss-newton-method.html#computation-of-the-chi-squared-function-1"><i class="fa fa-check"></i><b>2.1</b> Computation of the chi-squared function</a></li>
<li class="chapter" data-level="2.2" data-path="the-gauss-newton-method.html"><a href="the-gauss-newton-method.html#computation-of-the-gradient-1"><i class="fa fa-check"></i><b>2.2</b> Computation of the gradient</a></li>
<li class="chapter" data-level="2.3" data-path="the-gauss-newton-method.html"><a href="the-gauss-newton-method.html#the-parameter-updating-1"><i class="fa fa-check"></i><b>2.3</b> The parameter updating</a></li>
<li class="chapter" data-level="2.4" data-path="the-gauss-newton-method.html"><a href="the-gauss-newton-method.html#summary-and-comparison-to-gradient-descent"><i class="fa fa-check"></i><b>2.4</b> Summary and Comparison to Gradient Descent</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="levenberg-marquardt-lm-algorithm.html"><a href="levenberg-marquardt-lm-algorithm.html"><i class="fa fa-check"></i><b>3</b> Levenberg-Marquardt (LM) algorithm</a>
<ul>
<li class="chapter" data-level="3.1" data-path="levenberg-marquardt-lm-algorithm.html"><a href="levenberg-marquardt-lm-algorithm.html#the-damping-factor-lambda"><i class="fa fa-check"></i><b>3.1</b> The Damping Factor <span class="math inline">\(\lambda\)</span></a></li>
<li class="chapter" data-level="3.2" data-path="levenberg-marquardt-lm-algorithm.html"><a href="levenberg-marquardt-lm-algorithm.html#advantages-of-the-lm-algorithm"><i class="fa fa-check"></i><b>3.2</b> Advantages of the LM Algorithm</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="applying-the-lm-algorithm-to-a-damped-oscillation-model.html"><a href="applying-the-lm-algorithm-to-a-damped-oscillation-model.html"><i class="fa fa-check"></i><b>4</b> Applying the LM Algorithm to a Damped Oscillation Model</a>
<ul>
<li class="chapter" data-level="4.1" data-path="applying-the-lm-algorithm-to-a-damped-oscillation-model.html"><a href="applying-the-lm-algorithm-to-a-damped-oscillation-model.html#example-data"><i class="fa fa-check"></i><b>4.1</b> Example Data</a></li>
<li class="chapter" data-level="4.2" data-path="applying-the-lm-algorithm-to-a-damped-oscillation-model.html"><a href="applying-the-lm-algorithm-to-a-damped-oscillation-model.html#data-fitting-using-nlslm"><i class="fa fa-check"></i><b>4.2</b> Data fitting using nlsLM</a></li>
<li class="chapter" data-level="4.3" data-path="applying-the-lm-algorithm-to-a-damped-oscillation-model.html"><a href="applying-the-lm-algorithm-to-a-damped-oscillation-model.html#how-the-algorithm-works"><i class="fa fa-check"></i><b>4.3</b> How the Algorithm Works</a></li>
<li class="chapter" data-level="4.4" data-path="applying-the-lm-algorithm-to-a-damped-oscillation-model.html"><a href="applying-the-lm-algorithm-to-a-damped-oscillation-model.html#custom-implementation-of-the-algorithm"><i class="fa fa-check"></i><b>4.4</b> Custom Implementation of the Algorithm</a></li>
<li class="chapter" data-level="4.5" data-path="applying-the-lm-algorithm-to-a-damped-oscillation-model.html"><a href="applying-the-lm-algorithm-to-a-damped-oscillation-model.html#convergence-criteria-of-the-algorithm"><i class="fa fa-check"></i><b>4.5</b> Convergence Criteria of the Algorithm</a></li>
<li class="chapter" data-level="4.6" data-path="applying-the-lm-algorithm-to-a-damped-oscillation-model.html"><a href="applying-the-lm-algorithm-to-a-damped-oscillation-model.html#code-example"><i class="fa fa-check"></i><b>4.6</b> Code Example</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="applying-the-algorithm-to-a-sphere-function-model.html"><a href="applying-the-algorithm-to-a-sphere-function-model.html"><i class="fa fa-check"></i><b>5</b> Applying the Algorithm to a Sphere function model</a>
<ul>
<li class="chapter" data-level="5.1" data-path="applying-the-algorithm-to-a-sphere-function-model.html"><a href="applying-the-algorithm-to-a-sphere-function-model.html#code-explanation"><i class="fa fa-check"></i><b>5.1</b> Code Explanation</a></li>
<li class="chapter" data-level="5.2" data-path="applying-the-algorithm-to-a-sphere-function-model.html"><a href="applying-the-algorithm-to-a-sphere-function-model.html#example-data-1"><i class="fa fa-check"></i><b>5.2</b> Example data</a></li>
<li class="chapter" data-level="5.3" data-path="applying-the-algorithm-to-a-sphere-function-model.html"><a href="applying-the-algorithm-to-a-sphere-function-model.html#optimization-with-the-algorithm"><i class="fa fa-check"></i><b>5.3</b> Optimization with the Algorithm</a></li>
<li class="chapter" data-level="5.4" data-path="applying-the-algorithm-to-a-sphere-function-model.html"><a href="applying-the-algorithm-to-a-sphere-function-model.html#applying-the-algorithm"><i class="fa fa-check"></i><b>5.4</b> Applying the Algorithm</a></li>
<li class="chapter" data-level="5.5" data-path="applying-the-algorithm-to-a-sphere-function-model.html"><a href="applying-the-algorithm-to-a-sphere-function-model.html#code-example-1"><i class="fa fa-check"></i><b>5.5</b> Code Example</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="applying-the-lm-algorithm-to-lba-data.html"><a href="applying-the-lm-algorithm-to-lba-data.html"><i class="fa fa-check"></i><b>6</b> Applying the LM Algorithm to LBA data</a>
<ul>
<li class="chapter" data-level="6.1" data-path="applying-the-lm-algorithm-to-lba-data.html"><a href="applying-the-lm-algorithm-to-lba-data.html#pl-curve"><i class="fa fa-check"></i><b>6.1</b> 5 PL curve</a></li>
<li class="chapter" data-level="6.2" data-path="applying-the-lm-algorithm-to-lba-data.html"><a href="applying-the-lm-algorithm-to-lba-data.html#data-set"><i class="fa fa-check"></i><b>6.2</b> Data set</a></li>
<li class="chapter" data-level="6.3" data-path="applying-the-lm-algorithm-to-lba-data.html"><a href="applying-the-lm-algorithm-to-lba-data.html#initial-parameter-estimation"><i class="fa fa-check"></i><b>6.3</b> Initial parameter estimation</a></li>
<li class="chapter" data-level="6.4" data-path="applying-the-lm-algorithm-to-lba-data.html"><a href="applying-the-lm-algorithm-to-lba-data.html#example-of-code"><i class="fa fa-check"></i><b>6.4</b> Example of Code</a></li>
<li class="chapter" data-level="6.5" data-path="applying-the-lm-algorithm-to-lba-data.html"><a href="applying-the-lm-algorithm-to-lba-data.html#visualization-of-the-fitting-process"><i class="fa fa-check"></i><b>6.5</b> Visualization of the fitting process</a></li>
<li class="chapter" data-level="6.6" data-path="applying-the-lm-algorithm-to-lba-data.html"><a href="applying-the-lm-algorithm-to-lba-data.html#result"><i class="fa fa-check"></i><b>6.6</b> Result</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="evaluation-of-the-custom-code.html"><a href="evaluation-of-the-custom-code.html"><i class="fa fa-check"></i><b>7</b> Evaluation of the custom code</a></li>
<li class="chapter" data-level="" data-path="closing-remarks.html"><a href="closing-remarks.html"><i class="fa fa-check"></i>Closing Remarks</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Non-linear regression</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="levenberg-marquardt-lm-algorithm" class="section level1 hasAnchor" number="3">
<h1><span class="header-section-number">Chapter 3</span> Levenberg-Marquardt (LM) algorithm<a href="levenberg-marquardt-lm-algorithm.html#levenberg-marquardt-lm-algorithm" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>The Levenberg-Marquardt (LM) algorithm is a combination of two optimization techniques: the <strong>Gauss-Newton method</strong> and the <strong>gradient descent method</strong>. It is designed to minimize a non-linear least squares problem, often encountered in regression and curve fitting.</p>
<ul>
<li>The <strong>Gauss-Newton method</strong> is efficient for problems where the residuals are small and the function can be approximated by a quadratic model. However, the Gauss-Newton method can perform poorly when the function is highly non-linear, or if the initial guess for the parameters is far from the optimal solution.</li>
<li>The <strong>gradient descent method</strong> is more robust and works well even with large non-linearities, but it may require many iterations to converge, especially when the gradient is very small.</li>
</ul>
<p>The LM algorithm smoothly interpolates between the two methods. When the current solution is far from the optimal, it behaves more like gradient descent. As the solution improves and the model becomes more linear, the algorithm shifts towards the Gauss-Newton method. This hybrid approach provides the stability of gradient descent and the efficiency of Gauss-Newton.</p>
<p>The LM algorithm can be summarized in the following steps:</p>
<ol style="list-style-type: decimal">
<li><p><strong>Initialization</strong>: Choose an initial guess <span class="math inline">\(\theta_{\text{old}}\)</span> and set the damping factor <span class="math inline">\(\lambda_0\)</span> to a small positive value.</p></li>
<li><p><strong>Iteration</strong>: Repeat the following steps until convergence:</p></li>
</ol>
<ul>
<li><p>Compute the Jacobian matrix <span class="math inline">\(J\)</span> and the residual vector <span class="math inline">\(r = y - \hat{y}(\alpha)\)</span>.</p></li>
<li><p>Compute the Gauss-Newton step with the damping factor:</p>
<p><span class="math display">\[
  h_{\text{lm}} =  \left( J^T W J + \lambda I \right)^{-1} J^T  Wr
  \]</span></p></li>
<li><p>Update the parameter vector:</p>
<p><span class="math display">\[
  \theta_{\text{new}} = \theta_{\text{old}} + h_{\text{lm}}
  \]</span></p></li>
<li><p>If the new cost function is smaller than the previous one, decrease <span class="math inline">\(\lambda\)</span>; otherwise, increase <span class="math inline">\(\lambda\)</span>.</p></li>
</ul>
<ol start="3" style="list-style-type: decimal">
<li><p><strong>Convergence</strong>: The algorithm stops when the change in the cost function or the parameter vector is sufficiently small.</p></li>
<li><p><strong>Marquardt</strong> suggested later to modify the algorithm :</p></li>
</ol>
<p><span class="math display">\[
\theta_{\text{new}} = \theta_{\text{old}} + \left( J^T W J + \lambda \ diag(J^TWJ) \right)^{-1} J^T W r
\]</span></p>
<div id="the-damping-factor-lambda" class="section level2 hasAnchor" number="3.1">
<h2><span class="header-section-number">3.1</span> The Damping Factor <span class="math inline">\(\lambda\)</span><a href="levenberg-marquardt-lm-algorithm.html#the-damping-factor-lambda" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>The damping factor <span class="math inline">\(\lambda\)</span> adjusts the size of the update step. If the current solution is far from the optimum, a larger <span class="math inline">\(\lambda\)</span> will force the algorithm to behave more like gradient descent, ensuring a more stable update. Conversely, as the solution improves and the model becomes linear, <span class="math inline">\(\lambda\)</span> is reduced, and the algorithm behaves more like Gauss-Newton, which converges faster.</p>
<p>The update rule for <span class="math inline">\(\lambda\)</span> is typically based on the change in the cost function between iterations:</p>
<ul>
<li><p>If the new cost function <span class="math inline">\(\chi^2(\alpha_{\text{new}})\)</span> is smaller than the previous cost function <span class="math inline">\(\chi^2(\alpha_{\text{old}})\)</span>, then reduce <span class="math inline">\(\lambda\)</span> to speed up convergence.</p></li>
<li><p>If the new cost function <span class="math inline">\(\chi^2(\alpha_{\text{new}})\)</span> is larger than the previous one, increase <span class="math inline">\(\lambda\)</span> to make the algorithm behave more like gradient descent.</p></li>
</ul>
</div>
<div id="advantages-of-the-lm-algorithm" class="section level2 hasAnchor" number="3.2">
<h2><span class="header-section-number">3.2</span> Advantages of the LM Algorithm<a href="levenberg-marquardt-lm-algorithm.html#advantages-of-the-lm-algorithm" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<ul>
<li><strong>Efficiency</strong>: The LM algorithm is more efficient than pure gradient descent when the problem is approximately linear, and more robust than Gauss-Newton for non-linear problems.</li>
<li><strong>Stability</strong>: By adjusting the damping factor, the LM algorithm can avoid large updates that could cause divergence, which is a common problem in Gauss-Newton.</li>
<li><strong>Versatility</strong>: The LM algorithm is widely used in various applications, including curve fitting, machine learning, and computer vision.</li>
</ul>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="the-gauss-newton-method.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="applying-the-lm-algorithm-to-a-damped-oscillation-model.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
  "sharing": {
    "github": false,
    "facebook": true,
    "twitter": true,
    "linkedin": false,
    "weibo": false,
    "instapaper": false,
    "vk": false,
    "whatsapp": false,
    "all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
  },
  "fontsettings": {
    "theme": "white",
    "family": "sans",
    "size": 2
  },
  "edit": {
    "link": "https://github.com/USERNAME/REPO/edit/BRANCH/03-TheLM.Rmd",
    "text": "Edit"
  },
  "history": {
    "link": null,
    "text": null
  },
  "view": {
    "link": null,
    "text": null
  },
  "download": ["_main.HTML"],
  "search": {
    "engine": "fuse",
    "options": null
  },
  "toc": {
    "collapse": "subsection"
  }
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
