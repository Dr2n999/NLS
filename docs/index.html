<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Non-linear regression</title>
  <meta name="description" content="<p>This is a minimal example of using the bookdown package to write a book.
set in the _output.yml file.
The HTML output format for this example is bookdown::gitbook,</p>" />
  <meta name="generator" content="bookdown 0.42 and GitBook 2.6.7" />

  <meta property="og:title" content="Non-linear regression" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="<p>This is a minimal example of using the bookdown package to write a book.
set in the _output.yml file.
The HTML output format for this example is bookdown::gitbook,</p>" />
  <meta name="github-repo" content="rstudio/bookdown-demo" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Non-linear regression" />
  
  <meta name="twitter:description" content="<p>This is a minimal example of using the bookdown package to write a book.
set in the _output.yml file.
The HTML output format for this example is bookdown::gitbook,</p>" />
  

<meta name="author" content="Kyungmin In, GCCL" />


<meta name="date" content="2025-04-01" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  

<link rel="next" href="author.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<link href="libs/htmltools-fill-0.5.8.1/fill.css" rel="stylesheet" />
<script src="libs/htmlwidgets-1.6.4/htmlwidgets.js"></script>
<script src="libs/plotly-binding-4.10.4/plotly.js"></script>
<script src="libs/typedarray-0.1/typedarray.min.js"></script>
<link href="libs/crosstalk-1.2.1/css/crosstalk.min.css" rel="stylesheet" />
<script src="libs/crosstalk-1.2.1/js/crosstalk.min.js"></script>
<link href="libs/plotly-htmlwidgets-css-2.11.1/plotly-htmlwidgets.css" rel="stylesheet" />
<script src="libs/plotly-main-2.11.1/plotly-latest.min.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Non-linear regression</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Non-Linear Regression and Optimization Methods in LBA Data Analysis</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#key-optimization-methods-in-non-linear-regression"><i class="fa fa-check"></i>Key Optimization Methods in Non-Linear Regression</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#the-levenberg-marquardt-algorithm-a-hybrid-approach"><i class="fa fa-check"></i>The Levenberg-Marquardt Algorithm: A Hybrid Approach</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#why-should-we-care-about-these-optimization-methods"><i class="fa fa-check"></i>Why Should We Care About These Optimization Methods?</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#practical-implementation-in-r"><i class="fa fa-check"></i>Practical Implementation in R</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="author.html"><a href="author.html"><i class="fa fa-check"></i>Author</a></li>
<li class="chapter" data-level="1" data-path="the-gradient-descent-method.html"><a href="the-gradient-descent-method.html"><i class="fa fa-check"></i><b>1</b> The Gradient descent method</a>
<ul>
<li class="chapter" data-level="1.1" data-path="the-gradient-descent-method.html"><a href="the-gradient-descent-method.html#computation-of-the-chi-squared-function"><i class="fa fa-check"></i><b>1.1</b> Computation of the chi-squared function</a></li>
<li class="chapter" data-level="1.2" data-path="the-gradient-descent-method.html"><a href="the-gradient-descent-method.html#computation-of-the-gradient"><i class="fa fa-check"></i><b>1.2</b> Computation of the gradient</a></li>
<li class="chapter" data-level="1.3" data-path="the-gradient-descent-method.html"><a href="the-gradient-descent-method.html#the-parameter-updating"><i class="fa fa-check"></i><b>1.3</b> The parameter updating</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="the-gauss-newton-method.html"><a href="the-gauss-newton-method.html"><i class="fa fa-check"></i><b>2</b> The Gauss-Newton Method</a>
<ul>
<li class="chapter" data-level="2.1" data-path="the-gauss-newton-method.html"><a href="the-gauss-newton-method.html#computation-of-the-chi-squared-function-1"><i class="fa fa-check"></i><b>2.1</b> Computation of the chi-squared function</a></li>
<li class="chapter" data-level="2.2" data-path="the-gauss-newton-method.html"><a href="the-gauss-newton-method.html#computation-of-the-gradient-1"><i class="fa fa-check"></i><b>2.2</b> Computation of the gradient</a></li>
<li class="chapter" data-level="2.3" data-path="the-gauss-newton-method.html"><a href="the-gauss-newton-method.html#the-parameter-updating-1"><i class="fa fa-check"></i><b>2.3</b> The parameter updating</a></li>
<li class="chapter" data-level="2.4" data-path="the-gauss-newton-method.html"><a href="the-gauss-newton-method.html#summary-and-comparison-to-gradient-descent"><i class="fa fa-check"></i><b>2.4</b> Summary and Comparison to Gradient Descent</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="levenberg-marquardt-lm-algorithm.html"><a href="levenberg-marquardt-lm-algorithm.html"><i class="fa fa-check"></i><b>3</b> Levenberg-Marquardt (LM) algorithm</a>
<ul>
<li class="chapter" data-level="3.1" data-path="levenberg-marquardt-lm-algorithm.html"><a href="levenberg-marquardt-lm-algorithm.html#the-damping-factor-lambda"><i class="fa fa-check"></i><b>3.1</b> The Damping Factor <span class="math inline">\(\lambda\)</span></a></li>
<li class="chapter" data-level="3.2" data-path="levenberg-marquardt-lm-algorithm.html"><a href="levenberg-marquardt-lm-algorithm.html#advantages-of-the-lm-algorithm"><i class="fa fa-check"></i><b>3.2</b> Advantages of the LM Algorithm</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="applying-the-lm-algorithm-to-a-damped-oscillation-model.html"><a href="applying-the-lm-algorithm-to-a-damped-oscillation-model.html"><i class="fa fa-check"></i><b>4</b> Applying the LM Algorithm to a Damped Oscillation Model</a>
<ul>
<li class="chapter" data-level="4.1" data-path="applying-the-lm-algorithm-to-a-damped-oscillation-model.html"><a href="applying-the-lm-algorithm-to-a-damped-oscillation-model.html#example-data"><i class="fa fa-check"></i><b>4.1</b> Example Data</a></li>
<li class="chapter" data-level="4.2" data-path="applying-the-lm-algorithm-to-a-damped-oscillation-model.html"><a href="applying-the-lm-algorithm-to-a-damped-oscillation-model.html#data-fitting-using-nlslm"><i class="fa fa-check"></i><b>4.2</b> Data fitting using nlsLM</a></li>
<li class="chapter" data-level="4.3" data-path="applying-the-lm-algorithm-to-a-damped-oscillation-model.html"><a href="applying-the-lm-algorithm-to-a-damped-oscillation-model.html#how-the-algorithm-works"><i class="fa fa-check"></i><b>4.3</b> How the Algorithm Works</a></li>
<li class="chapter" data-level="4.4" data-path="applying-the-lm-algorithm-to-a-damped-oscillation-model.html"><a href="applying-the-lm-algorithm-to-a-damped-oscillation-model.html#custom-implementation-of-the-algorithm"><i class="fa fa-check"></i><b>4.4</b> Custom Implementation of the Algorithm</a></li>
<li class="chapter" data-level="4.5" data-path="applying-the-lm-algorithm-to-a-damped-oscillation-model.html"><a href="applying-the-lm-algorithm-to-a-damped-oscillation-model.html#convergence-criteria-of-the-algorithm"><i class="fa fa-check"></i><b>4.5</b> Convergence Criteria of the Algorithm</a></li>
<li class="chapter" data-level="4.6" data-path="applying-the-lm-algorithm-to-a-damped-oscillation-model.html"><a href="applying-the-lm-algorithm-to-a-damped-oscillation-model.html#code-example"><i class="fa fa-check"></i><b>4.6</b> Code Example</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="applying-the-algorithm-to-a-sphere-function-model.html"><a href="applying-the-algorithm-to-a-sphere-function-model.html"><i class="fa fa-check"></i><b>5</b> Applying the Algorithm to a Sphere function model</a>
<ul>
<li class="chapter" data-level="5.1" data-path="applying-the-algorithm-to-a-sphere-function-model.html"><a href="applying-the-algorithm-to-a-sphere-function-model.html#code-explanation"><i class="fa fa-check"></i><b>5.1</b> Code Explanation</a></li>
<li class="chapter" data-level="5.2" data-path="applying-the-algorithm-to-a-sphere-function-model.html"><a href="applying-the-algorithm-to-a-sphere-function-model.html#example-data-1"><i class="fa fa-check"></i><b>5.2</b> Example data</a></li>
<li class="chapter" data-level="5.3" data-path="applying-the-algorithm-to-a-sphere-function-model.html"><a href="applying-the-algorithm-to-a-sphere-function-model.html#optimization-with-the-algorithm"><i class="fa fa-check"></i><b>5.3</b> Optimization with the Algorithm</a></li>
<li class="chapter" data-level="5.4" data-path="applying-the-algorithm-to-a-sphere-function-model.html"><a href="applying-the-algorithm-to-a-sphere-function-model.html#applying-the-algorithm"><i class="fa fa-check"></i><b>5.4</b> Applying the Algorithm</a></li>
<li class="chapter" data-level="5.5" data-path="applying-the-algorithm-to-a-sphere-function-model.html"><a href="applying-the-algorithm-to-a-sphere-function-model.html#code-example-1"><i class="fa fa-check"></i><b>5.5</b> Code Example</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="applying-the-lm-algorithm-to-lba-data.html"><a href="applying-the-lm-algorithm-to-lba-data.html"><i class="fa fa-check"></i><b>6</b> Applying the LM Algorithm to LBA data</a>
<ul>
<li class="chapter" data-level="6.1" data-path="applying-the-lm-algorithm-to-lba-data.html"><a href="applying-the-lm-algorithm-to-lba-data.html#pl-curve"><i class="fa fa-check"></i><b>6.1</b> 5 PL curve</a></li>
<li class="chapter" data-level="6.2" data-path="applying-the-lm-algorithm-to-lba-data.html"><a href="applying-the-lm-algorithm-to-lba-data.html#data-set"><i class="fa fa-check"></i><b>6.2</b> Data set</a></li>
<li class="chapter" data-level="6.3" data-path="applying-the-lm-algorithm-to-lba-data.html"><a href="applying-the-lm-algorithm-to-lba-data.html#initial-parameter-estimation"><i class="fa fa-check"></i><b>6.3</b> Initial parameter estimation</a></li>
<li class="chapter" data-level="6.4" data-path="applying-the-lm-algorithm-to-lba-data.html"><a href="applying-the-lm-algorithm-to-lba-data.html#example-of-code"><i class="fa fa-check"></i><b>6.4</b> Example of Code</a></li>
<li class="chapter" data-level="6.5" data-path="applying-the-lm-algorithm-to-lba-data.html"><a href="applying-the-lm-algorithm-to-lba-data.html#visualization-of-the-fitting-process"><i class="fa fa-check"></i><b>6.5</b> Visualization of the fitting process</a></li>
<li class="chapter" data-level="6.6" data-path="applying-the-lm-algorithm-to-lba-data.html"><a href="applying-the-lm-algorithm-to-lba-data.html#result"><i class="fa fa-check"></i><b>6.6</b> Result</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="evaluation-of-the-custom-code.html"><a href="evaluation-of-the-custom-code.html"><i class="fa fa-check"></i><b>7</b> Evaluation of the custom code</a></li>
<li class="chapter" data-level="" data-path="closing-remarks.html"><a href="closing-remarks.html"><i class="fa fa-check"></i>Closing Remarks</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Non-linear regression</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="header">
<h1 class="title">Non-linear regression</h1>
<p class="author"><em>Kyungmin In, GCCL</em></p>
<p class="date"><em>2025-04-01</em></p>
</div>
<div id="non-linear-regression-and-optimization-methods-in-lba-data-analysis" class="section level1 unnumbered hasAnchor">
<h1>Non-Linear Regression and Optimization Methods in LBA Data Analysis<a href="index.html#non-linear-regression-and-optimization-methods-in-lba-data-analysis" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>Non-linear regression is an essential tool for modeling complex data in fields such as biochemistry, immunology, and diagnostics. In particular, when applying Ligand binding assay (<strong>LBA</strong>), such as Enzyme-Linked Immunosorbent Assay (<strong>ELISA</strong>), Electrochemiluminescence Immunoassay (<strong>ECLIA</strong>) data, the relationship between the concentration of a target analyte and the measured signal is often non-linear due to the intricate biochemical interactions that occur during the assay.</p>
<p>While linear regression models are typically used for simple linear relationships, ELISA data and other biological assays often require more sophisticated methods. The non-linear nature of the data necessitates using <strong>non-linear regression techniques</strong> to accurately model the underlying relationships. However, the challenge with non-linear regression lies in the fact that the relationship between variables cannot be directly expressed as a straight line, requiring iterative numerical methods to find the best-fitting model.</p>
<div id="key-optimization-methods-in-non-linear-regression" class="section level2 unnumbered hasAnchor">
<h2>Key Optimization Methods in Non-Linear Regression<a href="index.html#key-optimization-methods-in-non-linear-regression" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>The process of fitting a non-linear model to data involves finding the parameter values that minimize the difference between the predicted and observed data. The optimization methods used for this task can significantly affect the quality of the fit. Two popular techniques for solving non-linear regression problems are <strong>gradient descent</strong> and the <strong>Gauss-Newton method</strong>, both of which rely on iterative numerical optimization.</p>
<ul>
<li><p><strong>Gradient Descent</strong>: Gradient descent is a first-order optimization algorithm that adjusts the parameters of the model iteratively to reduce the error (often represented as a cost or loss function). In each step, it moves in the direction opposite to the gradient of the cost function, with the size of the step determined by the learning rate. Although simple and intuitive, gradient descent can be slow, and it may struggle to converge to the global minimum if the cost function is complex or contains many local minima.</p></li>
<li><p><strong>Gauss-Newton Method</strong>: The Gauss-Newton method is an optimization algorithm that is particularly useful for least-squares problems, such as those encountered in non-linear regression. It approximates the Hessian matrix (second-order derivatives) using the Jacobian matrix (first-order derivatives), which simplifies the computation and speeds up convergence compared to gradient descent. The Gauss-Newton method is more efficient than gradient descent when the model is close to the true solution, but it can struggle with highly non-linear models or when the initial guess is far from the optimal solution.</p></li>
</ul>
</div>
<div id="the-levenberg-marquardt-algorithm-a-hybrid-approach" class="section level2 unnumbered hasAnchor">
<h2>The Levenberg-Marquardt Algorithm: A Hybrid Approach<a href="index.html#the-levenberg-marquardt-algorithm-a-hybrid-approach" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>To overcome the limitations of those methods, the <strong>Levenberg-Marquardt algorithm</strong> (often referred to as <strong>LM algorithm</strong>) combines the advantages of both methods and has become a standard technique for solving non-linear least squares problems, including fitting LBA data.</p>
<p>The Levenberg-Marquardt algorithm adjusts the optimization process by blending gradient descent and Gauss-Newton. The idea is to take the best aspects of both methods, making it more robust and capable of handling difficult optimization problem by introducing a damping parameter that<br />
controls the balance between the gradient descent and Gauss-Newton steps.<br />
When the parameters are far from the optimal solution, the algorithm behaves more like gradient descent (which is stable but slower), and when the parameters are closer to the optimal solution, it behaves more like Gauss-Newton (which is faster but more sensitive to starting points).</p>
<p>Mathematically, the Levenberg-Marquardt update rule is given by:</p>
<p><span class="math display">\[
\theta_{\text{new}} = \theta_{\text{old}} +\left( J^T W J + \lambda I \right)^{-1} J^T  Wr
\]</span></p>
<p>Where:</p>
<ul>
<li><p><span class="math inline">\(\theta_{old}\)</span> is the current parameter estimates,</p></li>
<li><p><span class="math inline">\(J\)</span> is the Jacobian matrix of the residuals,</p></li>
<li><p><span class="math inline">\(\mathbf{r}_i\)</span>, - <span class="math inline">\(\lambda_i\)</span> is the damping parameter that adjusts the step size,</p></li>
<li><p><span class="math inline">\(I\)</span> is the identity matrix, and</p></li>
<li><p><span class="math inline">\(\mathbf{r}_i\)</span> represents the residuals (the difference between the model’s predictions and the observed data).</p></li>
</ul>
<p>The algorithm iteratively updates the parameters until the residuals are minimized, providing an accurate fit for non-linear models.</p>
</div>
<div id="why-should-we-care-about-these-optimization-methods" class="section level2 unnumbered hasAnchor">
<h2>Why Should We Care About These Optimization Methods?<a href="index.html#why-should-we-care-about-these-optimization-methods" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Understanding and applying non-linear regression, along with methods like gradient descent, Gauss-Newton, and Levenberg-Marquardt, is essential for researchers working with complex experimental data. In the case of LBA, the accuracy of the data fit directly impacts the sensitivity and reliability of the assay results. Inaccurate model fitting can lead to misleading conclusions, especially when quantifying low concentrations of analytes.</p>
<p>Moreover, the Levenberg-Marquardt algorithm’s robustness makes it a popular choice in many scientific and engineering applications, from pharmacokinetics to machine learning. By mastering these optimization methods, researchers can ensure more accurate, efficient, and reliable data analysis.</p>
</div>
<div id="practical-implementation-in-r" class="section level2 unnumbered hasAnchor">
<h2>Practical Implementation in R<a href="index.html#practical-implementation-in-r" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>To provide a hands-on understanding of the Levenberg-Marquardt algorithm and its application to LBA assay data analysis, I will walk through an example using <strong>custom R code</strong>. This code demonstrates how to implement non-linear regression using the Levenberg-Marquardt method, optimizing the parameters of <strong>a five-parameter logistic (5PL) model</strong> commonly used for ELISA data. The goal is to offer readers deeper understanding of non-linear regression.</p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>

<a href="author.html" class="navigation navigation-next navigation-unique" aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
  "sharing": {
    "github": false,
    "facebook": true,
    "twitter": true,
    "linkedin": false,
    "weibo": false,
    "instapaper": false,
    "vk": false,
    "whatsapp": false,
    "all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
  },
  "fontsettings": {
    "theme": "white",
    "family": "sans",
    "size": 2
  },
  "edit": {
    "link": "https://github.com/USERNAME/REPO/edit/BRANCH/index.Rmd",
    "text": "Edit"
  },
  "history": {
    "link": null,
    "text": null
  },
  "view": {
    "link": null,
    "text": null
  },
  "download": ["_main.HTML"],
  "search": {
    "engine": "fuse",
    "options": null
  },
  "toc": {
    "collapse": "subsection"
  }
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
